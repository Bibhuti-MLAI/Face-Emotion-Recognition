{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Face Emotion Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bibhuti-MLAI/Face-Emotion-Recognition/blob/main/Face_Emotion_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_7yk3Ww-F77"
      },
      "source": [
        "<h2 align=center> Face Emotion Recognition</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRUxBwtG-F8A"
      },
      "source": [
        "### Task 1: Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_LSegrS-wXV",
        "outputId": "9b9ba932-ee73-4c01-8bcd-244c8bb6b857"
      },
      "source": [
        "!pip install utils\n",
        "!pip install livelossplot"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: utils in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
            "Requirement already satisfied: livelossplot in /usr/local/lib/python3.7/dist-packages (0.5.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from livelossplot) (3.2.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from livelossplot) (5.5.0)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.7/dist-packages (from livelossplot) (2.3.3)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (21.3)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (3.13)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (2.11.3)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (2.8.2)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (5.1.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (3.10.0.2)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.9->bokeh->livelossplot) (2.0.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=16.8->bokeh->livelossplot) (3.0.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->bokeh->livelossplot) (1.15.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot) (0.8.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot) (0.7.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot) (1.0.18)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot) (57.4.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot) (5.1.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot) (4.4.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->livelossplot) (0.2.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->livelossplot) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->livelossplot) (0.11.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->livelossplot) (0.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvGxjjeV-9Ls",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c170aac8-1df5-4794-99a3-d772a3e0b27d"
      },
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import utils\n",
        "import os\n",
        "%matplotlib inline\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout,Flatten, Conv2D\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation, MaxPooling2D\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "from IPython.display import SVG, Image\n",
        "from livelossplot import PlotLossesKerasTF\n",
        "import tensorflow as tf\n",
        "print(\"Tensorflow version:\", tf.__version__)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version: 2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Effj8LiLABC0",
        "outputId": "3110196c-61fa-4233-d22a-19359919fed4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKHJxaffZA6G"
      },
      "source": [
        "#Giving the dataset\n",
        "train_data_dir = '/content/drive/MyDrive/Face Emotion Recognition - Bibhuti Bhusan Sahu/data/train'\n",
        "validation_data_dir = '/content/drive/MyDrive/Face Emotion Recognition - Bibhuti Bhusan Sahu/data/validation'\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Li6D8MYB-F8E"
      },
      "source": [
        "### Task 3: Generate Training and Validation Batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iri8ehFw-9Tj",
        "outputId": "00a1923f-7c91-4805-b4fb-a33623e29b82"
      },
      "source": [
        "img_size = 48\n",
        "batch_size = 64\n",
        "\n",
        "datagen_train = ImageDataGenerator(horizontal_flip=True)\n",
        "\n",
        "train_generator = datagen_train.flow_from_directory(\"/content/drive/MyDrive/Face Emotion Recognition - Bibhuti Bhusan Sahu/data/train\",\n",
        "                                                    target_size=(img_size,img_size),\n",
        "                                                    color_mode=\"grayscale\",\n",
        "                                                    batch_size=batch_size,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    shuffle=True)\n",
        "\n",
        "datagen_validation = ImageDataGenerator(horizontal_flip=True)\n",
        "validation_generator = datagen_validation.flow_from_directory(\"/content/drive/MyDrive/Face Emotion Recognition - Bibhuti Bhusan Sahu/data/validation\",\n",
        "                                                    target_size=(img_size,img_size),\n",
        "                                                    color_mode=\"grayscale\",\n",
        "                                                    batch_size=batch_size,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    shuffle=False)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 29346 images belonging to 7 classes.\n",
            "Found 12959 images belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daMzt6_V-F8G"
      },
      "source": [
        "### Task 4: Create CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kEfnJDR-F8G",
        "outputId": "639b2dc6-f018-41f4-e919-d3eda1fea0ca"
      },
      "source": [
        "# Initialising the CNN\n",
        "model = Sequential()\n",
        "\n",
        "# 1 - Convolution\n",
        "model.add(Conv2D(64,(3,3), padding='same', input_shape=(48, 48,1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# 2nd Convolution layer\n",
        "model.add(Conv2D(128,(5,5), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# 3rd Convolution layer\n",
        "model.add(Conv2D(512,(3,3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# 4th Convolution layer\n",
        "model.add(Conv2D(512,(3,3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Flattening\n",
        "model.add(Flatten())\n",
        "\n",
        "# Fully connected layer 1st layer\n",
        "model.add(Dense(256))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Fully connected layer 2nd layer\n",
        "model.add(Dense(512))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Dense(7, activation='softmax'))\n",
        "\n",
        "opt = Adam(lr=0.0005)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 48, 48, 64)        640       \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 48, 48, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 48, 48, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 24, 24, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 24, 24, 64)        0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 24, 24, 128)       204928    \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 24, 24, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 24, 24, 128)       0         \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 12, 12, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 12, 12, 128)       0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 12, 12, 512)       590336    \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 12, 12, 512)      2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 12, 12, 512)       0         \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 6, 6, 512)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 6, 6, 512)         0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 6, 6, 512)        2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 6, 6, 512)         0         \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 3, 3, 512)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 3, 3, 512)         0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 4608)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 256)               1179904   \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 256)              1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 512)               131584    \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 512)              2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 7)                 3591      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,478,727\n",
            "Trainable params: 4,474,759\n",
            "Non-trainable params: 3,968\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdAcmX-X-F8H"
      },
      "source": [
        "### Task 6: Train and Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vceL6IKD-F8I",
        "outputId": "42385599-981c-4fa8-e787-3e7623f306b2"
      },
      "source": [
        "%%time\n",
        "\n",
        "epochs = 15\n",
        "steps_per_epoch = train_generator.n//train_generator.batch_size\n",
        "validation_steps = validation_generator.n//validation_generator.batch_size\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
        "                              patience=2, min_lr=0.00001, mode='auto')\n",
        "checkpoint = ModelCheckpoint(\"model_weights.h5\", monitor='val_accuracy',\n",
        "                             save_weights_only=True, mode='max', verbose=1)\n",
        "callbacks = [PlotLossesKerasTF(), checkpoint, reduce_lr]\n",
        "\n",
        "history = model.fit(\n",
        "    x=train_generator,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=epochs,\n",
        "    validation_data = validation_generator,\n",
        "    validation_steps = validation_steps,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            " 12/458 [..............................] - ETA: 1:59:05 - loss: 2.2907 - accuracy: 0.1992"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bc4MxDsq-F8I"
      },
      "source": [
        "### Task 7: Represent Model as JSON String"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHw8ir7CVAE0"
      },
      "source": [
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}